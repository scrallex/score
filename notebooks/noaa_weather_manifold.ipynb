{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# NOAA Weather Bitstream Prototype\n",
        "\n",
        "This notebook fetches hourly observations from the National Weather Service API, encodes domain-aware weather bits, exports a candle JSON file compatible with the SEP `manifold_generator`, and inspects the resulting coherence/rupture metrics. Configure the station/date below and run the cells sequentially."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Imports and basic configuration\n",
        "\n",
        "Set the station identifier (ICAO), target UTC date, and output directory for intermediate artefacts. The script keeps everything inside `analysis/weather/` by default."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import json\n",
        "import os\n",
        "import subprocess\n",
        "from dataclasses import dataclass\n",
        "from datetime import datetime, timedelta, timezone\n",
        "from pathlib import Path\n",
        "from typing import Any, Dict, Iterable, List\n",
        "\n",
        "import pandas as pd\n",
        "import requests\n",
        "\n",
        "REPO_ROOT = Path.cwd().resolve()\n",
        "if REPO_ROOT.name == \"notebooks\":\n",
        "    REPO_ROOT = REPO_ROOT.parent\n",
        "OUTPUT_ROOT = (REPO_ROOT / \"analysis\" / \"weather\")\n",
        "OUTPUT_ROOT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "STATION_ID = os.environ.get(\"NOAA_STATION_ID\", \"KATT\")  # Camp Mabry, Austin\n",
        "TARGET_DATE = os.environ.get(\"NOAA_TARGET_DATE\", \"2025-10-01\")  # UTC date\n",
        "OBS_LIMIT = int(os.environ.get(\"NOAA_OBS_LIMIT\", \"500\"))  # generous upper bound per API request\n",
        "\n",
        "print(f\"Repository root: {REPO_ROOT}\")\n",
        "print(f\"Output directory: {OUTPUT_ROOT}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. NOAA API helpers\n",
        "\n",
        "`fetch_noaa_observations` issues a single request covering the chosen UTC day. The API responds with most-recent-first features, so we sort ascending before returning a tidy `pandas` frame."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "USER_AGENT = os.environ.get(\"NOAA_USER_AGENT\", \"SEP Weather Signal Prototype (ops@sepengine.com)\")\n",
        "SESSION = requests.Session()\n",
        "SESSION.headers.update({\n",
        "    \"User-Agent\": USER_AGENT,\n",
        "    \"Accept\": \"application/geo+json\",\n",
        "})\n",
        "\n",
        "API_ROOT = \"https://api.weather.gov\"\n",
        "\n",
        "def utc_bounds(date_str: str) -> tuple[str, str]:\n",
        "    start = datetime.fromisoformat(date_str).replace(tzinfo=timezone.utc)\n",
        "    end = start + timedelta(days=1) - timedelta(milliseconds=1)\n",
        "    return start.isoformat().replace(\"+00:00\", \"Z\"), end.isoformat().replace(\"+00:00\", \"Z\")\n",
        "\n",
        "\n",
        "def fetch_noaa_observations(station: str, date_str: str, limit: int = 1000) -> Dict[str, Any]:\n",
        "    start, end = utc_bounds(date_str)\n",
        "    params = {\n",
        "        \"start\": start,\n",
        "        \"end\": end,\n",
        "        \"limit\": min(limit, 1000),\n",
        "    }\n",
        "    url = f\"{API_ROOT}/stations/{station}/observations\"\n",
        "    resp = SESSION.get(url, params=params, timeout=60)\n",
        "    resp.raise_for_status()\n",
        "    return resp.json()\n",
        "\n",
        "\n",
        "def observations_to_frame(payload: Dict[str, Any]) -> pd.DataFrame:\n",
        "    features = payload.get(\"features\", [])\n",
        "    records: List[Dict[str, Any]] = []\n",
        "    for feat in features:\n",
        "        props = feat.get(\"properties\", {})\n",
        "        timestamp = props.get(\"timestamp\")\n",
        "        if not timestamp:\n",
        "            continue\n",
        "        temp = (props.get(\"temperature\") or {}).get(\"value\")\n",
        "        rh = (props.get(\"relativeHumidity\") or {}).get(\"value\")\n",
        "        pressure = (props.get(\"barometricPressure\") or {}).get(\"value\")\n",
        "        if temp is None or rh is None or pressure is None:\n",
        "            continue\n",
        "        records.append({\n",
        "            \"time\": pd.to_datetime(timestamp),\n",
        "            \"temperature_c\": temp,\n",
        "            \"relative_humidity\": rh,\n",
        "            \"pressure_pa\": pressure,\n",
        "        })\n",
        "    if not records:\n",
        "        raise ValueError(\"No usable observations in payload\")\n",
        "    frame = pd.DataFrame.from_records(records).dropna()\n",
        "    frame = frame.sort_values(\"time\").set_index(\"time\")\n",
        "    frame = frame[~frame.index.duplicated(keep=\"first\")]\n",
        "    return frame\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Fetch & resample observations\n",
        "\n",
        "The raw feed may contain sub-hourly updates. We align on a 60-minute grid using median aggregation and forward-fill to cover minor gaps."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "payload = fetch_noaa_observations(STATION_ID, TARGET_DATE, limit=OBS_LIMIT)\n",
        "frame_raw = observations_to_frame(payload)\n",
        "print(f\"Fetched {len(frame_raw)} observations spanning {frame_raw.index.min()} to {frame_raw.index.max()}\")\n",
        "\n",
        "frame_hourly = frame_raw.resample(\"1H\").median().ffill().dropna()\n",
        "print(f\"Hourly samples: {len(frame_hourly)}\")\n",
        "frame_hourly.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Encode trend bits and composite signal\n",
        "\n",
        "The bits follow the SEP/QFH weather sketch:\n",
        "\n",
        "- Temperature bit = 1 when temperature is non-decreasing.\n",
        "- Humidity bit = 1 when humidity is non-decreasing.\n",
        "- Pressure bit = 1 when pressure is falling.\n",
        "- Composite bit = majority vote across the three trends."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def compute_bits(frame: pd.DataFrame) -> pd.DataFrame:\n",
        "    df = frame.copy()\n",
        "    df[\"temp_bit\"] = (df[\"temperature_c\"] >= df[\"temperature_c\"].shift(1)).astype(int)\n",
        "    df[\"hum_bit\"] = (df[\"relative_humidity\"] >= df[\"relative_humidity\"].shift(1)).astype(int)\n",
        "    df[\"press_bit\"] = (df[\"pressure_pa\"] < df[\"pressure_pa\"].shift(1)).astype(int)\n",
        "    df[\"composite_bit\"] = (df[[\"temp_bit\", \"hum_bit\", \"press_bit\"]].sum(axis=1) >= 2).astype(int)\n",
        "    df = df.dropna()\n",
        "    return df\n",
        "\n",
        "bits_frame = compute_bits(frame_hourly)\n",
        "print(bits_frame[[\"temp_bit\", \"hum_bit\", \"press_bit\", \"composite_bit\"]].tail())\n",
        "print(f\"Composite bits: {bits_frame['composite_bit'].tolist()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Convert composite bits into candle JSON\n",
        "\n",
        "`manifold_generator` expects OHLCV candles. We synthesise candles where price moves up when the composite bit is 1 and down otherwise, with monotonically increasing volume to keep the derived QFH bit aligned with the composite sequence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def bits_to_candles(bits_df: pd.DataFrame, base_value: float = 0.0) -> List[Dict[str, Any]]:\n",
        "    candles: List[Dict[str, Any]] = []\n",
        "    if bits_df.empty:\n",
        "        return candles\n",
        "    first_time = bits_df.index[0] - timedelta(hours=1)\n",
        "    prev_close = base_value\n",
        "    prev_volume = 1000.0\n",
        "    candles.append({\n",
        "        \"timestamp\": int(first_time.timestamp() * 1000),\n",
        "        \"open\": prev_close,\n",
        "        \"high\": prev_close + 0.1,\n",
        "        \"low\": prev_close - 0.1,\n",
        "        \"close\": prev_close,\n",
        "        \"volume\": prev_volume,\n",
        "    })\n",
        "\n",
        "    for ts, row in bits_df.iterrows():\n",
        "        bit = int(row[\"composite_bit\"])\n",
        "        open_price = prev_close\n",
        "        delta = 1.0 if bit == 1 else -1.0\n",
        "        close_price = open_price + delta\n",
        "        high = max(open_price, close_price) + 0.05\n",
        "        low = min(open_price, close_price) - 0.05\n",
        "        prev_volume += 1.0\n",
        "        candle = {\n",
        "            \"timestamp\": int(ts.timestamp() * 1000),\n",
        "            \"open\": float(open_price),\n",
        "            \"high\": float(high),\n",
        "            \"low\": float(low),\n",
        "            \"close\": float(close_price),\n",
        "            \"volume\": float(prev_volume),\n",
        "        }\n",
        "        candles.append(candle)\n",
        "        prev_close = close_price\n",
        "    return candles\n",
        "\n",
        "candles = bits_to_candles(bits_frame)\n",
        "print(f\"Generated {len(candles)} candles\")\n",
        "\n",
        "candle_path = OUTPUT_ROOT / f\"{STATION_ID}_{TARGET_DATE}.candles.json\"\n",
        "with candle_path.open(\"w\", encoding=\"utf-8\") as handle:\n",
        "    json.dump(candles, handle, indent=2)\n",
        "\n",
        "print(f\"Candles written to {candle_path}\")\n",
        "\n",
        "candles[:3]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Run the native manifold generator\n",
        "\n",
        "We invoke the compiled `bin/manifold_generator`, pointing it at the candle JSON. The command writes a manifold snapshot for inspection."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "manifold_path = OUTPUT_ROOT / f\"{STATION_ID}_{TARGET_DATE}.manifold.json\"\n",
        "cmd = [str(REPO_ROOT / \"bin\" / \"manifold_generator\"), \"--input\", str(candle_path), \"--output\", str(manifold_path)]\n",
        "print(\"Running:\", \" \".join(cmd))\n",
        "result = subprocess.run(cmd, check=False, capture_output=True, text=True)\n",
        "print(\"stdout:\", result.stdout)\n",
        "print(\"stderr:\", result.stderr)\n",
        "if result.returncode != 0:\n",
        "    raise RuntimeError(f\"manifold_generator failed with exit code {result.returncode}\")\n",
        "print(f\"Manifold stored at {manifold_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Inspect \u03bb / rupture metrics\n",
        "\n",
        "Load the manifold JSON and examine the most recent signal to confirm hazard values respond to the composite bit flips."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "with manifold_path.open(\"r\", encoding=\"utf-8\") as handle:\n",
        "    manifold = json.load(handle)\n",
        "\n",
        "signals = manifold.get(\"signals\", [])\n",
        "print(f\"Signal count: {len(signals)}\")\n",
        "\n",
        "if signals:\n",
        "    last = signals[-1]\n",
        "    metrics = last.get(\"metrics\", {})\n",
        "    display({\n",
        "        \"timestamp_ns\": last.get(\"timestamp_ns\"),\n",
        "        \"signature\": last.get(\"repetition\", {}).get(\"signature\"),\n",
        "        \"coherence\": metrics.get(\"coherence\"),\n",
        "        \"stability\": metrics.get(\"stability\"),\n",
        "        \"entropy\": metrics.get(\"entropy\"),\n",
        "        \"rupture\": metrics.get(\"rupture\"),\n",
        "        \"lambda_hazard\": last.get(\"lambda_hazard\", metrics.get(\"rupture\")),\n",
        "        \"count_1h\": last.get(\"repetition\", {}).get(\"count_1h\"),\n",
        "    })\n",
        "else:\n",
        "    print(\"No signals emitted. Check the candle payload length.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Optional: plot composite bits vs hazard\n",
        "\n",
        "Visualise the composite bit timeline alongside rupture/\u03bb to spot transitions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "if signals:\n",
        "    signal_frame = pd.DataFrame([{**sig.get(\"metrics\", {}), \"lambda_hazard\": sig.get(\"lambda_hazard\"), \"timestamp_ns\": sig.get(\"timestamp_ns\")}\n",
        "                                 for sig in signals])\n",
        "    signal_frame[\"timestamp\"] = pd.to_datetime(signal_frame[\"timestamp_ns\"], unit=\"ns\", utc=True)\n",
        "    merged = bits_frame.reset_index()\n",
        "    timestamp_col = merged.columns[0]\n",
        "    merged = merged.rename(columns={timestamp_col: \"timestamp\"})\n",
        "    merged[\"timestamp\"] = pd.to_datetime(merged[\"timestamp\"], utc=True)\n",
        "    fig, ax1 = plt.subplots(figsize=(10, 4))\n",
        "    ax1.step(merged[\"timestamp\"], merged[\"composite_bit\"], where=\"post\", label=\"Composite Bit\", color=\"tab:blue\")\n",
        "    ax1.set_ylabel(\"Composite Bit\", color=\"tab:blue\")\n",
        "    ax1.set_ylim(-0.1, 1.1)\n",
        "    ax2 = ax1.twinx()\n",
        "    ax2.plot(signal_frame[\"timestamp\"], signal_frame[\"lambda_hazard\"], marker=\"o\", label=\"\u03bb\", color=\"tab:red\")\n",
        "    ax2.set_ylabel(\"\u03bb / rupture\", color=\"tab:red\")\n",
        "    ax2.set_ylim(0, 1)\n",
        "    fig.autofmt_xdate()\n",
        "    fig.tight_layout()\n",
        "    plot_path = OUTPUT_ROOT / f\"{STATION_ID}_{TARGET_DATE}_lambda.png\"\n",
        "    fig.savefig(plot_path, dpi=150, bbox_inches=\"tight\")\n",
        "    print(f\"Saved plot to {plot_path}\")\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Skipping plot\u2014no manifold signals available.\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}