# Reality Filter Report — whitepaper_demo

## KPIs

- **approved**: 3
- **blocked**: 2
- **repaired**: 2
- **hallucination_rate**: 0.4
- **repair_yield**: 0.5
- **citation_coverage**: 1.0
- **latency_ms_p50**: 93.31
- **latency_ms_p90**: 99.944
- **latency_ms_budget**: 120.0
- **latency_budget_breach_rate**: 0.0

## Permutation Test

Observed coverage 0.000 with p-value 1.0000.

## Threshold Sweep (top coverage)

| r_min | lambda_max | sigma_min | coverage | admitted | total |
| --- | --- | --- | --- | --- | --- |
| 1 | 0.12 | 0.15 | 0.000 | 0 | 5 |

Full CSV: results/sweeps/whitepaper_demo.csv

## Evaluation Metrics

- **macro_f1**: 0.35555555555555557
- **baseline_macro_f1**: 0.6049382716049383
- **macro_f1_delta**: -0.24938271604938272
- **dev_macro_f1**: 0.5663956639566395
- **sanity_flags_count**: 0
- **metrics.total**: 24
- **metrics.hallucination_rate**: 0.16666666666666666
- **metrics.repair_yield**: 0.20833333333333334
- **metrics.citation_coverage**: 0.0
- **best_thresholds**:
  - r_min: 1
  - lambda_max: 0.12
  - sigma_min: 0.15
  - structural_threshold: 0.46
  - semantic_threshold: 0.25

## Before vs After Examples

### WHITU037 (UNVERIFIABLE → UNVERIFIABLE)

**Question:** What policy covers 'unverified_claim_037'?

**Baseline:** I cannot find any information about unverified_claim_037.

**Filtered:** unverified_claim_037

---
### WHITS031 (SUPPORTED → UNVERIFIABLE)

**Question:** What does the documentation state about 'lambda'?

**Baseline:** The documentation states that lambda is covered in detail.

**Filtered:** The documentation states that lambda is covered in detail

---
### WHITS047 (SUPPORTED → UNVERIFIABLE)

**Question:** What does the documentation state about 'telemetry'?

**Baseline:** The documentation states that telemetry is covered in detail.

**Filtered:** The documentation states that telemetry is covered in detail

---
### WHITU033 (UNVERIFIABLE → UNVERIFIABLE)

**Question:** What policy covers 'unverified_claim_033'?

**Baseline:** I cannot find any information about unverified_claim_033.

**Filtered:** I cannot find any information about unverified_claim_033

---
### WHITS007 (SUPPORTED → UNVERIFIABLE)

**Question:** What does the documentation state about 'twin'?

**Baseline:** The documentation states that twin is covered in detail.

**Filtered:** The documentation states that twin is covered in detail

---
### WHITR009 (REFUTED → UNVERIFIABLE)

**Question:** Is it correct that 'filter' is explicitly denied in the pack?

**Baseline:** The documentation explicitly denies filter.

**Filtered:** The documentation explicitly denies filter

---
### WHITS030 (SUPPORTED → UNVERIFIABLE)

**Question:** What does the documentation state about 'from'?

**Baseline:** The documentation states that from is covered in detail.

**Filtered:** The documentation states that from is covered in detail

---
### WHITS032 (SUPPORTED → UNVERIFIABLE)

**Question:** What does the documentation state about 'logistics'?

**Baseline:** The documentation states that logistics is covered in detail.

**Filtered:** The documentation states that logistics is covered in detail

---
### WHITR012 (REFUTED → REFUTED)

**Question:** Is it correct that 'instruct' is explicitly denied in the pack?

**Baseline:** The documentation explicitly denies instruct.

**Filtered:** instruct (see doc://whitepaper#instruct)

---
### WHITR005 (REFUTED → UNVERIFIABLE)

**Question:** Is it correct that 'before' is explicitly denied in the pack?

**Baseline:** The documentation explicitly denies before.

**Filtered:** No supporting evidence.

---
---
Generated by scripts/reality_filter_report.py

## FEVER Truth Pack & Reliability Head Update (2025-10-06)

- Rebuilt the FEVER train truth pack with fast theme-graph metrics:
  - Manifest: `analysis/truth_packs/fever_train_full_final/manifest.json`
  - Content hash: `blake2b:0394a79f3545f8d2bd8301f669962f12`
  - ANN index verified via `sep_text_manifold.cli similar` (top hits: `"analyze"`, `"dolittle"`).
- One-epoch reliability-head fine-tune on the refreshed `eval_detail.jsonl`:
  - Command: `python scripts/train_reliability_attn.py results/eval/fever_train_full/eval_detail.jsonl --epochs 1 --batch-size 32 --learning-rate 1e-3 --val-ratio 0.05`
  - Validation metrics — precision: **0.538**, recall: **1.000**, F1: **0.700**, Brier: **0.249**, ECE: **0.0069**.
  - Checkpoint written to `results/models/fever_reliability.pt` for downstream experiments and curriculum runs.

### Reliability calibration sweep (FEVER dev)

- Baseline checkpoint (`results/models/fever_reliability.pt`) evaluated on `results/eval/fever_dev/eval_detail.jsonl`; summary at `results/analysis/reliability_fever_dev_summary.json`.
  - Metrics: precision **0.333**, recall **1.000**, F1 **0.500**, Brier **0.267**, ECE **0.212**.
  - Exhaustive admit/margin sweep (`results/analysis/reliability_precision_targets.json`) produced **no operating point ≥0.90 precision**; the best candidate stayed at 0.333 precision with 100% recall (full coverage, zero filtering).
  - PR curve diagnostic: see `docs/figures/fever_reliability_pr_curve.png`.

### Reliability head v2 fine-tune (3 epochs on 5k FEVER train sample)

- Command executed: `python scripts/train_reliability_attn.py results/eval/fever_train_sample5k.jsonl --epochs 3 --batch-size 64 --learning-rate 8e-4 --val-ratio 0.10 --calibrate-thresholds --output-checkpoint results/models/fever_reliability_v2.pt --device cpu`.
- Validation metrics at epoch 3: precision **0.753**, recall **1.000**, F1 **0.859**, Brier **0.139**, ECE **0.041**.
- Dev evaluation for `results/models/fever_reliability_v2.pt` (`results/analysis/reliability_fever_dev_v2_summary.json`): precision **0.500**, recall **1.000**, F1 **0.667**, Brier **0.193**, ECE **0.132**.
- Threshold grid search (`results/analysis/reliability_v2_precision_targets.json`, `results/analysis/reliability_v2_precision_scan.json`) still found **no ≥0.90 precision** operating point; highest observed precision was **0.667** at admit threshold ≈`0.7066`, margin ≥`-0.5`, but recall collapsed to **0.0009** (9 admissions).
- Updated PR curves: `docs/figures/fever_reliability_v2_pr_curve.png`.

### High-confidence span samples (v2 predictions)

- FEVER_dev_12738 — “Australia (2008 film) … Bowen.” → cites `wiki://Australia_-LRB-2008_film-RRB-#4`, `wiki://Bowen,_Queensland#0`.
- FEVER_dev_96239 — “23 percent of the University of Mississippi's students …” → cites `wiki://University_of_Mississippi#4`.
- FEVER_dev_86459 — “South African Communist Party … Tripartite Alliance.” → cites `wiki://South_African_Communist_Party#2`, `wiki://Congress_of_South_African_Trade_Unions#0`, `wiki://Tripartite_Alliance#0`, `wiki://African_National_Congress#0`.
- FEVER_dev_186590 — “In 1971 Asylum Records …” → cites `wiki://Asylum_Records#0`.
- FEVER_dev_42620 — “The Stanford prison experiment was funded by … ONR.” → cites `wiki://Stanford_prison_experiment#2`, `wiki://Office_of_Naval_Research#0`.
- FEVER_dev_140750 — “In Kentucky, the electric chair … electrocution.” → cites `wiki://Electric_chair#15`.
- FEVER_dev_99395 — “Woodrow Wilson lived during World War I … Wilsonianism.” → cites `wiki://Woodrow_Wilson#3`.

### /seen latency benchmark (FEVER pack)

- Server: `PYTHONPATH=src uvicorn scripts.reality_filter_service:app --host 0.0.0.0 --port 8000` (log suppressed).
- Load test: `PYTHONPATH=src python scripts/benchmark_seen.py --manifest analysis/truth_packs/fever_train_full_final/manifest.json --requests 200 --concurrency 8 --url http://127.0.0.1:8000`.
- Results: throughput **≈616 rps**, latency **p50 10.7 ms**, **p90 11.6 ms**, 0 errors, 200/200 successes.
